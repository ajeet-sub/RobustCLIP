{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6969cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import clip\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "from clip.simple_tokenizer import SimpleTokenizer\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "#from triplet_loss import TripletLoss\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10a35178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "n_epochs = 20\n",
    "testsize=0.1\n",
    "# Step 1: Define a tensor and apply transformations first\n",
    "temp = torch.tensor(0.07)\n",
    "\n",
    "batch_size=128\n",
    "model_save_dr=\"/home/hice1/mmoradi6/scratch/RCLIP/models/\"\n",
    "prob=0 #contamination level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca3bc197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_data = pd.read_csv('/home/hice1/mmoradi6/scratch/RCLIP/data/cleaned_train.csv', index_col='id')\n",
    "df_labels=pd.read_csv('/home/hice1/mmoradi6/scratch/RCLIP/data/sampled_labels.csv',index_col=\"attribute_id\")\n",
    "image_dir=\"/home/hice1/mmoradi6/scratch/RCLIP/data/training_data/\"\n",
    "# image_names=sorted(os.listdir(image_dir))\n",
    "# Get the set of valid image IDs (with extension)\n",
    "image_names = list(df_data.index)\n",
    "image_names=[i+\".png\" for i in image_names]\n",
    "# Result\n",
    "train_names, test_names, _, _ = train_test_split(image_names, image_names, test_size=testsize, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43349b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tokenizer = SimpleTokenizer()\n",
    "\n",
    "# Copied from https://github.com/openai/CLIP/blob/beba48f35392a73c6c47ae67ddffced81ad1916d/clip/clip.py#L164\n",
    "# but with relaxed exception\n",
    "def tokenize(texts, context_length: int = 77) -> torch.LongTensor:\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    sot_token = _tokenizer.encoder[\"<|startoftext|>\"]\n",
    "    eot_token = _tokenizer.encoder[\"<|endoftext|>\"]\n",
    "    all_tokens = [[sot_token] + _tokenizer.encode(text) + [eot_token] for text in texts]\n",
    "    result = torch.zeros(len(all_tokens), context_length, dtype=torch.long)\n",
    "\n",
    "    for i, tokens in enumerate(all_tokens):\n",
    "        n = min(len(tokens), context_length)\n",
    "        result[i, :n] = torch.tensor(tokens)[:n]\n",
    "        if len(tokens) > context_length:\n",
    "            result[i, -1] = tokens[-1]\n",
    "\n",
    "    return result\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df_data, train_names,df_labels):\n",
    "        super().__init__()\n",
    "        self.df_data = df_data\n",
    "        self.train_names = train_names\n",
    "        self.df_labels=df_labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.train_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name=self.train_names[idx]\n",
    "        image_path=image_dir+image_name\n",
    "        text_ids_string=df_data.loc[image_name[:-4]].iloc[0] #ids of text input as string e.g. '123 143'\n",
    "        #corruption with probability prob\n",
    "        random_number=torch.rand(1)\n",
    "        if random_number<prob:\n",
    "            name_random=random.choice(self.train_names)\n",
    "            text_ids_string=df_data.loc[name_random[:-4]].iloc[0] #randomly choose the labels from another image\n",
    "        text_ids_string_list=text_ids_string.split(\" \")\n",
    "        text_list=[df_labels.loc[int(ii)].iloc[0].split(\"::\")[1] for ii in text_ids_string_list]\n",
    "\n",
    "        image = preprocess(Image.open(image_path)) \n",
    "        text_all = ', '.join(text_list)\n",
    "        text=tokenize([text_all])[0]\n",
    "        return image, text\n",
    "    \n",
    "    \n",
    "class RollingMean():\n",
    "    def __init__(self):\n",
    "        self.n = 0\n",
    "        self.mean = 0\n",
    "        \n",
    "    def update(self, value):\n",
    "        self.mean = (self.mean * self.n + value) / (self.n+1)\n",
    "        self.n += 1\n",
    "        \n",
    "    def result(self):\n",
    "        return self.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9cf4fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CLIP\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device, jit=False)\n",
    "\n",
    "# Get embedding size\n",
    "embed_dim = model.text_projection.shape[1]\n",
    "embed_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e796b752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "dstrain = MyDataset(df_data, train_names,df_labels)\n",
    "dltrain = DataLoader(dstrain, batch_size=batch_size, num_workers=0)\n",
    "#test data\n",
    "dstest=MyDataset(df_data, test_names,df_labels)\n",
    "dltest = DataLoader(dstest, batch_size=batch_size, num_workers=0)\n",
    "# params = list(model.parameters()) + list(temp) #parameters\n",
    "#optim=(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "#optim = torch.optim.AdamW(model.parameters(), lr=1e-4, eps=1e-8, weight_decay=1e-2)\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.2)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optim, 1e-2, total_steps=n_epochs * (2*len(dltrain)-1),\n",
    "                                               base_momentum=0.0, max_momentum=0.5, pct_start=0.1, div_factor=1e2, final_div_factor=1e4)\n",
    "# criterion = TripletLoss(device)\n",
    "criterion=torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c4248f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c3691998a94e24bee8309fed5c0146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f3c92e7f47481c80543ae7b677ac9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6801c8de6d3044efad9459236c06af5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "loss_test=[]\n",
    "# If temp is a float or Python scalar:\n",
    "if not isinstance(temp, torch.Tensor):\n",
    "    temp = torch.tensor(temp, device=device)\n",
    "else:\n",
    "    temp = temp.to(device)\n",
    "scale = torch.exp(temp)\n",
    "for epoch in range(n_epochs):\n",
    "    if epoch%5==0 & epoch>0:\n",
    "        torch.save(model.state_dict(), model_save_dr+str(100*prob)+str(epoch)+\".pth\")\n",
    "    loss_test_aux=[]\n",
    "    with tqdm(total=len(dltrain)) as bar:\n",
    "        loss_mean = RollingMean()\n",
    "        for images, texts in dltrain:\n",
    "            # Generate train and text features\n",
    "            I_e = model.encode_image(images.to(device)) #multimodal features\n",
    "            T_e = model.encode_text(texts.to(device))\n",
    "            T_e = T_e / T_e.norm(2, dim=1, keepdim=True) #normalize\n",
    "            I_e = I_e / I_e.norm(2, dim=1, keepdim=True) #normalize\n",
    "            \n",
    "            \n",
    "            optim.zero_grad()\n",
    "            #calculate logits, this loss function is based on the original paper\n",
    "            logits_i = I_e@ T_e.T * scale\n",
    "            logits_t = T_e@ I_e.T * scale\n",
    "            labels = torch.arange(images.size(0)).to(device)\n",
    "            loss_i = criterion(logits_i, labels)\n",
    "            loss_t = criterion(logits_t, labels)\n",
    "            loss = (loss_i + loss_t)/2\n",
    "            # Join train and test features\n",
    "            #features = torch.hstack([images_features, texts_features])\n",
    "            \n",
    "            # L2-normalize features\n",
    "            #features = features / features.norm(2, dim=1, keepdim=True)\n",
    "\n",
    "            # Apply Triplet SemiHardLoss\n",
    "            #loss = criterion(features, targets)\n",
    "\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Update metric and progress bar\n",
    "            loss_mean.update(loss.item())\n",
    "            bar.update()\n",
    "            bar.set_description('{:.4f}'.format(loss_mean.result()))\n",
    "    #Update loss test for test data\n",
    "    with tqdm(total=len(dltest)) as bar:\n",
    "        for images, texts in dltest:\n",
    "            I_e = model.encode_image(images.to(device)) #multimodal features\n",
    "            T_e = model.encode_text(texts.to(device))\n",
    "            T_e = T_e / T_e.norm(2, dim=1, keepdim=True) #normalize\n",
    "            I_e = I_e / I_e.norm(2, dim=1, keepdim=True) #normalize\n",
    "            #calculate logits, this loss function is based on the original paper\n",
    "            logits_i = I_e@ T_e.T * scale\n",
    "            logits_t = T_e@ I_e.T * scale\n",
    "            labels = torch.arange(images.size(0)).to(device)\n",
    "            loss_i = criterion(logits_i, labels)\n",
    "            loss_t = criterion(logits_t, labels)\n",
    "            loss_test_aux.append(((loss_i + loss_t)/2).item())\n",
    "            bar.update()\n",
    "    #print(loss_test_aux)\n",
    "    loss_test.append(np.mean(loss_test_aux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bafe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot test progress\n",
    "# Convert tensors to Python numbers\n",
    "# losses_test_plot = [loss.item() for loss in loss_test]\n",
    "\n",
    "# Plot as usual\n",
    "x_axis=[iii for iii in range(1,n_epochs+1,1)]\n",
    "plt.plot(loss_test, label='Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Test loss')\n",
    "plt.title('Test loss progress over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2926570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "# Assuming `model` is an instance of the CLIP class\n",
    "torch.save(model.state_dict(), model_save_dr+\"all_data\"+str(100*prob)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac8213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e67fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
