{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6969cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import clip\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a35178",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43349b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 1. CIFAR‑10 batch loading ────────────────────────────────────────────────\n",
    "CIFAR_CLASSES = [\n",
    "    \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "    \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
    "]\n",
    "\n",
    "def unpickle_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f, encoding=\"bytes\")\n",
    "\n",
    "def load_cifar(root):\n",
    "    xs, ys = [], []\n",
    "    for batch_name in [f\"data_batch_{i}\" for i in range(1, 6)] + [\"test_batch\"]:\n",
    "        data = unpickle_file(os.path.join(root, batch_name))\n",
    "        xs.append(data[b\"data\"])\n",
    "        ys.extend(data[b\"labels\"])\n",
    "    X = np.vstack(xs).astype(np.uint8)  # (60000, 3072)\n",
    "    y = np.array(ys, dtype=np.int64)   # (60000,)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cf4fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 2. Tokenizer for CLIP text ───────────────────────────────────────────────\n",
    "_tokenizer = clip.simple_tokenizer.SimpleTokenizer()\n",
    "def tokenize(texts, context_length: int = 77) -> torch.LongTensor:\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    sot = _tokenizer.encoder[\"<|startoftext|>\"]\n",
    "    eot = _tokenizer.encoder[\"<|endoftext|>\"]\n",
    "    all_tokens = [[sot] + _tokenizer.encode(t) + [eot] for t in texts]\n",
    "    result = torch.zeros(len(all_tokens), context_length, dtype=torch.long)\n",
    "    for i, tokens in enumerate(all_tokens):\n",
    "        length = min(len(tokens), context_length)\n",
    "        result[i, :length] = torch.tensor(tokens[:length])\n",
    "        if len(tokens) > context_length:\n",
    "            result[i, -1] = tokens[-1]\n",
    "    return result\n",
    "\n",
    "# ── 3. Dataset with optional label corruption ────────────────────────────────\n",
    "class CIFARDataset(Dataset):\n",
    "    def __init__(self, X, y, indices, transform, prob=0.0):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.indices = indices\n",
    "        self.transform = transform\n",
    "        self.prob = prob\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        k = self.indices[idx]\n",
    "        img_arr = self.X[k].reshape(3, 32, 32).transpose(1, 2, 0)\n",
    "        img = Image.fromarray(img_arr, mode=\"RGB\")\n",
    "\n",
    "        # label corruption with probability prob\n",
    "        if random.random() < self.prob:\n",
    "            label = self.y[random.choice(self.indices)]\n",
    "        else:\n",
    "            label = self.y[k]\n",
    "\n",
    "        img = self.transform(img)\n",
    "        text_prompt = f\"a photo of a {CIFAR_CLASSES[label]}\"\n",
    "        text = tokenize(text_prompt)[0]\n",
    "        return img, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e796b752",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_root = \"/home/hice1/asubramanian91/scratch/cifar-10-batches-py\"\n",
    "X, y = load_cifar(cifar_root)\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    np.arange(len(X)), test_size=0.2, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "# load CLIP and its preprocessing\n",
    "model, preprocess_clip = clip.load(\"ViT-B/32\", device=device, jit=False)\n",
    "model = model.to(device).float() \n",
    "\n",
    "# add data augmentations before CLIP's preprocess\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "    preprocess_clip\n",
    "])\n",
    "\n",
    "batch_size = 256\n",
    "prob = 0.05  # label corruption probability\n",
    "\n",
    "train_ds = CIFARDataset(X, y, train_idx, transform, prob=prob)\n",
    "test_ds  = CIFARDataset(X, y, test_idx,  transform, prob=0.0)\n",
    "\n",
    "dltrain = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "dltest  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1fe629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 5. Optimizer & Scheduler & Loss ──────────────────────────────────────────\n",
    "head_names = {\"visual_projection\", \"text_projection\", \"logit_scale\"}\n",
    "head_params, backbone_params = [], []\n",
    "for name, p in model.named_parameters():\n",
    "    if name.split(\".\")[0] in head_names:\n",
    "        head_params.append(p)\n",
    "    else:\n",
    "        backbone_params.append(p)\n",
    "\n",
    "optim = torch.optim.AdamW(\n",
    "    [\n",
    "        {\"params\": head_params,     \"lr\": 1e-4, \"weight_decay\": 0.2},\n",
    "        {\"params\": backbone_params, \"lr\": 3e-5, \"weight_decay\": 0.2},\n",
    "    ],\n",
    "    betas=(0.9, 0.98), eps=1e-8\n",
    ")\n",
    "\n",
    "n_epochs = 20\n",
    "warmup_steps = 500\n",
    "total_steps = n_epochs * len(dltrain)\n",
    "\n",
    "def lr_lambda(step):\n",
    "    if step < warmup_steps:\n",
    "        return (step + 1) / warmup_steps\n",
    "    progress = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n",
    "    return 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# initialise logit_scale safely\n",
    "with torch.no_grad():\n",
    "    model.logit_scale.fill_(math.log(1 / 0.07))\n",
    "    model.logit_scale.clamp_(0, math.log(100))\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c4248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-6\n",
    "LOGIT_CLAMP = math.log(100)\n",
    "\n",
    "class RollingMean:\n",
    "    def __init__(self): self.count = 0; self.avg = 0.0\n",
    "    def update(self, v):\n",
    "        self.avg = (self.avg * self.count + v) / (self.count + 1)\n",
    "        self.count += 1\n",
    "    def __call__(self): return self.avg\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    # Training\n",
    "    model.train()\n",
    "    rm = RollingMean()\n",
    "    with tqdm(dltrain, desc=f\"Epoch {epoch}/{n_epochs}\") as bar:\n",
    "        for images, texts in bar:\n",
    "            images, texts = images.to(device), texts.to(device)\n",
    "            \n",
    "            I_e = model.encode_image(images)\n",
    "            T_e = model.encode_text(texts)\n",
    "\n",
    "            if torch.isnan(I_e).any() or torch.isnan(T_e).any():\n",
    "                print(\"↯ NaN in embedding! I_e:\", I_e[torch.isnan(I_e)], \n",
    "                      \"T_e:\", T_e[torch.isnan(T_e)])\n",
    "                break\n",
    "            \n",
    "            I_e = F.normalize(I_e, dim=1, eps=EPS)\n",
    "            T_e = F.normalize(T_e, dim=1, eps=EPS)\n",
    "\n",
    "            # debug: after normalization?\n",
    "            if torch.isinf(I_e).any() or torch.isinf(T_e).any():\n",
    "                print(\"↯ Inf after normalize! I_e:\", I_e[torch.isinf(I_e)],\n",
    "                      \"T_e:\", T_e[torch.isinf(T_e)])\n",
    "                break\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model.logit_scale.data.clamp_(0, LOGIT_CLAMP)\n",
    "            logit_scale = model.logit_scale.exp()\n",
    "\n",
    "            # debug: logit_scale okay?\n",
    "            if not torch.isfinite(logit_scale):\n",
    "                print(\"↯ Bad logit_scale:\", model.logit_scale.data, \"exp:\", logit_scale)\n",
    "                break\n",
    "\n",
    "            logits_i = I_e @ T_e.T * logit_scale\n",
    "            logits_t = T_e @ I_e.T * logit_scale\n",
    "\n",
    "            # debug: logits\n",
    "            if torch.isnan(logits_i).any() or torch.isinf(logits_i).any():\n",
    "                print(\"↯ Bad logits_i:\", logits_i[~torch.isfinite(logits_i)])\n",
    "                break\n",
    "            labels = torch.arange(images.size(0), device=device)\n",
    "\n",
    "            loss = 0.5 * (criterion(logits_i, labels) + criterion(logits_t, labels))\n",
    "\n",
    "            optim.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optim.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            rm.update(loss.item())\n",
    "            bar.set_postfix(train_loss=f\"{rm():.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad(), tqdm(dltest, desc=\"Val  \", leave=False) as bar:\n",
    "        for images, texts in bar:\n",
    "            images, texts = images.to(device), texts.to(device)\n",
    "            \n",
    "            I_e = model.encode_image(images)\n",
    "            T_e = model.encode_text(texts)\n",
    "            I_e = F.normalize(I_e, dim=1, eps=EPS)\n",
    "            T_e = F.normalize(T_e, dim=1, eps=EPS)\n",
    "\n",
    "            model.logit_scale.data.clamp_(0, LOGIT_CLAMP)\n",
    "            logit_scale = model.logit_scale.exp()\n",
    "\n",
    "            logits_i = I_e @ T_e.T * logit_scale\n",
    "            logits_t = T_e @ I_e.T * logit_scale\n",
    "            labels = torch.arange(images.size(0), device=device)\n",
    "\n",
    "            val_loss = 0.5 * (criterion(logits_i, labels) + criterion(logits_t, labels))\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "    mean_val = float(np.mean(val_losses))\n",
    "    loss_history.append(mean_val)\n",
    "    print(f\"   ✦ Validation loss: {mean_val:.4f}\")\n",
    "\n",
    "print(\"Done! Validation losses:\", loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e67fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
